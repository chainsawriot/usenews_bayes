---
title             : "The Bayesian turn in comparative content analysis"
shorttitle        : "BAYESIAN MULTILEVEL REGRESSION"

author: 
  - name          : "Chung-hong Chan"
    affiliation   : "1"
    corresponding : yes
    address       : "A5, 6 (section A), 68159 Mannheim, Germany"
    email         : "chung-hong.chan@mzes.uni-mannheim.de"
  - name          : "Adrian Rauschfleisch"
    affiliation   : "2"    

affiliation:
  - id            : "1"
    institution   : "Mannheimer Zentrum für Europäische Sozialforschung, Universität Mannheim, Germany"
  - id            : "2"
    institution   : "National Taiwan University, Taiwan"
    
authornote: |
  The authors would like to thank professor Kasper Welbers (Vrije Universiteit Amsterdam) for his advice on the development of the Dutch dictionary; Dr Junior Yuner Zhu (City University of Hong Kong) for sharing details about her study.
  Source code and data are available at (redacted). Prereg: https://osf.io/2h4w8/

abstract: |
  The purpose of this paper is to argue that researchers should refrain from using current (frequentist) analytical approaches to analyze data from a comparative content analysis. It is because current approaches cannot account for non-atomicity (nested nature) and non-stochasticity (non-random sampling) of the data. Bayesian multilevel regression is suggested to be a, and probably, the only, valid analytical approach. Using the openly available useNews data and the R package brms, we demonstrate how to apply such approach for the analysis of comparative content analysis. We also address common queries of the approach such as choosing the prior distribution and diagnosing the convergence of the model.
  
keywords          : "Bayesian inference, multilevel model, comparative content analysis, ecological effect"
wordcount         : "0"

bibliography      : ["manuscript.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
figsintext        : yes
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output:
  papaja::apa6_pdf:
    latex_engine: xelatex
---

```{r setup, include = FALSE}
library("papaja")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```


*"The comparative approach attempts to reach conclusions beyond single cases and explains differences and similarities between objects of analysis against the backdrop of their contextual conditions."* @esser:2017:CRM

Comparative content analysis is a frequently used research design in journalism studies. Comparative content analysis is used in modeling journalistic culture [e.g. @esser:2013:C], comparative news value research [e.g. @burggraaff:2017:T;@wilke:2012], news flow research [e.g. @wu:2000:SDI], among others. A typical comparative content analysis in journalism research includes news articles from various outlets and usually also from various countries. Then the included news articles are coded either manually or automatically. Although some comparative content analysis studies are purely descriptive, most of these studies are aimed to study how contextual conditions such as characteristics of media outlets (e.g. political orientation, online versus offline) and their countries (e.g. post-communist country) influence the content of news articles. For example, some hypotheses are "the coverage of foreign countries by the news is primarily  determined  by  geographical  proximity  and  the  status  of  the  covered  country" [@wilke:2012, p.306] and "the  degree  of  opinion-orientation  will  be  highest  in  newspapers  from  Polarized  Mediterranean systems and lowest in those from Anglo-American systems." [@esser:2013:C] Employing the language from epidemiology [@susser:1994], the effect on media content in these hypotheses is assumed to be ecological. It assumes a macro contextual factor (e.g. newspapers from Polarized Mediterranean systems) is associated with an outcome at the micro-level (e.g. degree of opinion-orientation), namely, the article-level.

This study of ecological effect on individual behaviours has a long tradition in social sciences. A famous example was Émile Durkheim’s investigation on the ecological factors associated with suicide. Durkheim found the higher suicide rate among citizens from Scandinvian countries than those from other European countries. Using today’s standard, Durkheim’s analysis is descriptive and this descriptive approach for studying ecological effect is indeed still useful for hypothesis generation in comparative content analysis. An example of hypothesis-generating comparative content analysis is @chan2020combining, in which the sentiment profiles of terrorism coverage from Muslim- and Christian-majority countries were visualized. Hypothesis-generating comparative content analysis, however, is rare. Most studies have a confirmatory outlook. As we see from the example hypotheses above, most of these studies propose hypotheses to test for ecological effects. In this context usually traditional (frequentist) hypothesis testing approaches were used: @esser:2013:C lumped multiple outlets from the same country together and then used univariate analysis of variance to test for the differences in the proportion of opinion-orienting articles across countries. In @wu:2000:SDI, multiple stepwise regression was used. These approaches violate the underlying assumptions of the statistical analyses. It highlights the fact that comparative content analysis introduces a feature that researchers usually overlook: media contents are clustered in multilevel. A news article is nested within its media outlet and its media outlet is in turn nested within its country. Theoretically with a large enough sample it can be argued that a news article is nested within authors. Such data structure brings two problems: non-atomicity and non-stochasticity.


## Non-atomicity

*"When it comes to regression, multilevel regression deserves to be the default approach"* @mcelreath2020statistical [p. 356]

It is perhaps well-known what ecological fallacy is. We commit ecological fallacy, when we make inference at micro-level (e.g. Eating more chocolate makes one cleverer) based on macro-level data (e.g. the correlation between countries' chocolate consumption and countries' number of Nobel winners). The reverse of ecological fallacy, i.e. making inference at macro-level based on micro-level data, is equally fallacious. This fallacy is called atomistic fallacy [@gnaldi:2018:EFC].

In a comparative content analysis, it is easy to incorrectly assume that macro-level independent variables (e.g. Anglo-American systems) could be analyzed at the same level as the micro-level dependent variable (e.g. the  degree of opinion-orientation). The manifestation of this incorrect assumption is to enter macro-level variables as independent variables in multiple regression analysis and regress them against a micro-level dependent variable. Suppose one wants to study how the probability of covering China changes when the hosting country of the media outlet has a higher trade volume with China. In the following regression equation, let $y_{i}$ be the dependent variable at the micro-level (coverage of China or not) and $x_{i}$ be the independent variable at the macro-level (trade volume with China). Suppose there are $m$ news articles where $i = 1,2,\ldots,m$.

\begin{align}
  y_{i} = \beta_{0} + \beta_{1} x_{i} + \epsilon_{i}
\end{align}

This method is the so-called "disaggregation approach". From an epistemic standpoint, searching for ecological effect by studying the value of slope ($\beta_{1}$) leads to atomistic fallacy [@hox2017multilevel]. From a statistical standpoint, this approach violates the underlying independence assumption. Almost all frequentist statistical tests assume that the observations are independent of each other. It is unrealistic to assume articles from the same media outlet are independent: they are subjected to being edited by the same editorial team, to being written by the same group of journalists exposed to the same journalistic culture and paid for by the same employer. Also, the way communication researchers collect their media content resembles cluster sampling rather than random sampling: one usually starts from a specific media outlet and then collects all relevant articles from it. The choice of media outlets or countries are almost always not randomly selected. [^1] This sampling approach makes the independence assumption even more fragile.

[^1]: If countries were randomly selected, we shall see more African countries in comparative works. It is because 1/4, or 54 out of 195, UN countries are in Africa.

Previous simulation studies have shown that ignoring this dependence can lead to false-positive associations [e.g. @clarke:2008:W;@chen:2012:IIL]. The problem is more severe when the dependent variable is a discrete binary variable [@clarke:2008:W], a common feature of content analysis. [^2]

[^2]: Some communication researchers apply the disaggregation approach by justifying the intraclass correlation between groups is small and the impact of ignoring the multilevel structure is also small [a finding in @chen:2012:IIL], see an example in @zhu:2020:S [footnote 5]. Even a multilevel modeling textbook avocates this justification [@bickel2007multilevel]. We reject this justification because it violates the independence assumption and thus commits atomistic fallacy. See also @nezlek:2008:IMM for a criticism of such justification. 

There are two solutions to this. The first solution is to aggregate the micro-level dependent variable across a macro-level inpendent variable. Suppose there are $n$ countries in the above example. One can aggregate the total number of articles covering China as $z_{k}$ for the $k$-th country, where $k=i,\ldots,n$. Then, we can do a count-based regression with a regression equation like so:

\begin{equation}
  \label{eq:2}
  \log{z_{k}} = \beta_{0} + \beta_{1} x_{k} + \epsilon_{k}
\end{equation}

Using this aggregation method, the unit of analysis effectively switches from article to country. This method is useful when $x$ is the only independent variable, akin @esser:2013:C. It is not technically committing atomistic fallacy, when one uses the value of slope as the evidence for an ecological effect. However, this method still has important drawbacks. First, it cannot be used for data with more than two levels. In @esser:2013:C, for example, multiple media outlets from the same country were lumped together and in effect, assumed to be homogenous and the information about media outlets was discarded. Second, this method discards a massive amount of information. It is better for analysis of a dependent micro-level variable with a reasonably aggregation function (e.g. counting a binary variable). For numerical variables, aggregation functions such as taking a mean or median cannot capture the spread of the micro-level variable [@bryk:1988:H]. Also, the effective sample size is reduced from the number of articles ($m$) to the number of countries ($n$). Nonetheless, this aggregation method, although inflexible, is still useful when the number of groups (e.g. $n$) is large. It is also useful to collapse micro-levels (e.g. article-level) that are not useful in answering one’s research questions.

Another solution is to use the multilevel model (linear mixed model, or hierarchical model). In a multilevel model, the effect on micro-level dependent variable ($y$) is modeled with equations at different levels. Using the above example, $y_{ik}$ denotes whether the $i$-th article in the $j$-th country is covering China; $x_{k}$ denotes the trade volume with China of the $k$-th country where the media outlet of $i$-th article is located. 

\begin{align}
  y_{ik} &= \beta_{0} + \epsilon_{ik} \\
  \beta_{0} &= \gamma_{00} + \gamma_{01} x_{k} + \mu_{0k}
\end{align}

In these equations, $\gamma_{00}$ is the average slope, while $\mu_{0k}$ is group-dependent deviations of the slope from the average. It is usually set as having a normal distribution with a variance $\tau_{00}$, i.e. $\mu_{0k} \sim \mathcal{N}(0, \tau_{00})$. Instead of a single value, regression coefficient $\gamma_{00}$ is assumed to be a distribution of values depending on a macro-level group. It addresses the problem of clustering of articles by macro-level variables. This model is called the varying-intercept model and is used frequently in social science research. We can then study the magnitude of $\gamma_{01}$ to determine the ecological effect.

The benefit of using multilevel modeling lies in its flexibility in handling multi-level data. Suppose we also want to consider the clustering of articles around $o$ different media outlets in the above example and $j$-th media outlet is the media outlet of the $i$-th article, where $j = 1,\ldots, o$. The multilevel regression equations are rewritten as:

\begin{align}
y_{ijk} &= \pi_{0} + \epsilon_{ijk} \\
\pi_{0} &= \beta_{00} + \mu_{0j} \\
\beta_{00} &= \gamma_{000} + \mu_{00k} + \gamma_{001} x_{k}
\end{align}

This flexibility is demonstrated in the study by @rinke:2016:ISB. He studied the likelihood of opinion justification in 1559 utterances nested in 329 news items, which were in turn nested in 101 news broadcasts. Multilevel logistic regression was used to model the natural three-level hierarchy of his data.

Multilevel modeling is the way to go for analyzing non-atomic data from comparative content analysis. However, the conventional approach for statistical inference makes it not optimal.

## Non-stochasticity

*"Statisticians, like artists, have the bad habit of falling in love with their models."* George E.P. Box

The conventional approach for statistical inference in multilevel modeling is maximum likelihood estimation (MLE). @stegmueller:2013:HMC demonstrates that MLE is associated with shrinkage (reduction of standard error, i.e. more false positive) and the shrinkage is more severe when the number of macro-level units (e.g. countries) is small. @stegmueller:2013:HMC proposes to use Bayesian analysis as a robust alternative [see counterarguments from @elff:2020:MAF;@bryan:2015:MMC]. Although less restrictive methods such as restricted maximum likelihood (REML) have been demonstrated to remediate the shrinkage issue of MLE [@elff:2020:MAF], we still agree with Stegmueller’s proposal for theoretical reasons. Our argument is more in line with @western:1994:BIC.

Before diving into our theoretical reasoning, it is important to revisit what frequentist inference, the current default but often misunderstood [@rinke:2018:PMA] mode of inference in communication science, is. Under the frequentist framework, each experiment is assumed to be one of infinite independent, **repeatable** experiments on randomly drawn samples from the population. Based on this assumption and with just one experiment, we make an estimation about the population. The discrepancy between the estimation from that one experiment and the actual value of the population is due to sampling error alone, i.e. which subjects were randomly sampled from the population. Randomized surveys, for examples, are assumed to be repeatable through repeated random sampling of the population. Suppose we replicated the same survey for 100 times and we would obtain a slightly different sample every time. We then calculated the 90\% confidence interval of the mean for each of these 100 surveys. We should anticipate that more or less 90 out of these 100 confidence intervals would include the true mean of the population. We cannot say for sure exactly 90 out of these 100 confidence intervals would include the true mean of the population because repeated random sampling is indeed random and the process is **stochastic**. However, we can say 90 is more probable than says, 0 or 100.

Comparative content analysis, unlike randomized surveys or randomized media experiments, usually collects all available data. In contrast to sampling, these studies are actually doing census of all data and there is no way to get more data unless the scope of these studies is changed [@berk:1995:SIA]. It is especially true for modern large-N studies using automated content analytic techniques. @burggraaff:2017:T, for instance, "collected all available news items from a selection of major Dutch news outlets, both online and print" (p. 6) and that amounted to 762,095 articles from 9 outlets in the period of 2014-2015. 
Census-style studies are not repeatable and thus they generate non-stochastic data. In other words, data from comparative content analysis are fundamentally irrelevant for frequentist inference [@western:1994:BIC]. P-values and confidence intervals generated do not have the same meaning as those from repeatable studies. According to @western:1994:BIC [p. 413], these values from non-stochastic data "lack meaning even as abstract propositions".

Following arguments from @western:1994:BIC and @stegmueller:2013:HMC for comparative studies, Bayesian inference should be used for analyzing data from comparative content analysis.

## Bayesian analysis

*"PROBABILITY DOES NOT EXIST."* Bruno de Finetti

What is the probability for this paper being accepted by *Digital Journalism*? Under the frequentist framework (and if *Digital Journalism* were accepting papers stochastically), we can only find this out by repeatedly submitting this paper to *Digital Journalism*, say for 100 times, and then count the frequency of acceptance in these repeated submissions. It is indeed impractical as well as inhumane to the editorial team of *Digital Journalism*. Instead, we assert before submission that this paper has a probability of 24% for being accepted. That is the published acceptance rate from *Digital Journalism*’s website. After this paper is submitted and is not desk rejected, the probability might be around 24% to 30%. After a month of waiting and our confidence is shaken a little, the probability might decrease to 10% to 20%. After the paper is favorably reviewed by two reviewers and an R&R is invited, the probability might increase to 40% to 60%. If you see this paper under the "Latest articles" section of *Digital Journalism*'s website, then the probability is beyond doubt 100% (or 0% if we submit this paper again).

Without repeated experiment, these probabilities quantify our certainty on how likely this paper is being accepted, given the current available data. We revise our old beliefs (or **prior**, $p(\theta)$) with the new data ($X$) and form our revised belief (or **posterior**, $p(\theta|X)$). This can be summarize in the following equation [@gelman2020bayesian]:

\begin{align}
	P(\theta | X) \propto  P(\theta) P(X| \theta)
\end{align}
 
The $P(X| \theta)$ part is called likelihood function. In the $Digital Journalism$ example, the likelihood function is based on rough rules from our experience and thus is not systematic. In actual analysis, we need to derive such likelihood function based on the available data using methods such as Markov Chain Monte Carlo (MCMC). Nonetheless, the above equation indicates that there are only three ingredients in any Bayesian analysis: 1) data ($X$), 2) a method to derive the likelihood function $P(X | \theta)$ from the data, and 3) prior, $P(\theta)$. 

We skip elaborating part 1, because some, but certainty not all, researchers have the means to amass a massive amount. The mechanism of how part 2 can be used to derive the likelihood function is beyond the scope of this paper. <!-- We provide a tutorial in Appendix I(+++TODO) for those who want to get an intuition. --> The current standard method, MCMC, is much more computationally intensive and has only been possible on desktop computer since mid-1990s [@robert:2011:SHM]. And only in the last few years that can be done efficiently [@hoffman2014no], thanks to the probablistic programming language *Stan* [@gelman:2015:S]. R interfaces to Stan, such as *brms* [@burkner2017advanced], make Bayesian analysis even more accessible to R users. But still, it is important to be mindful that Bayesian analysis is much more computational intensive than methods such as MLE. Our benchmark suggests that Bayesian analysis needs at least 100 times more running time than MLE.

Part 3 (Prior) is arguably the most controversial part of Bayesian analysis. In the *Digital Journalism* example, we can select a reasonable prior (or **informative** prior) of 24% from published information. More often than not, we do not have any information to set an informative prior (e.g. What about *Journal of Communication*?). One option is to consult experts or to make an educated guess. But one person's expert opinion could be another person's wishful thinking. And this perceived subjectivity of specifying priors attracts wide-spread criticism from both statisticians [e.g. @efron1986isn] and social scientists [@elff:2020:MAF;@bryan:2015:MMC].

Undoubtedly, setting prior is consequential to the analysis [@van:2006:PB]. But the influence from prior is greatly weakened, when the data is getting bigger. Also, one can select a weakly informative prior [@lemoine:2019:M] which only specifies the possible range of the posterior [^4]. Some so-called "default weakly informative priors", e.g. $\mathcal{t}(1, 0, 0.25)$, have been suggested for typical regression models [@gelman:2008]. The documentation of Stan also provides information on how to choose an appropriate prior (https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations). 

[^4]: One could also use a completely *noninformative* prior such as $\mathcal{U}(-\infty, \infty)$. It is, however, no longer advised.

## Bayesian communication research

*"There is a general challenge to a prescription of more widespread use of Bayesian methods for multilevel modelling, and that is that such methods require statistical expertise beyond that of most applied social science researchers, as well as specialist software (or software with which such researchers are unfamiliar)."* @bryan:2015:MMC [p. 19]

Bayesian analysis is still a minority statistical method in social sciences. It is reasonable to say that Bayesian analysis is extremely rare in our field. Although some communication researchers adopted the method [e.g. @kovic:2017:B;@chan2020high] these studies are not comparative. As far as we know, the only available comparative content analysis that Bayesian multilevel regression was used for studying ecological effect is @leeuw:2020:AAT. We believe comparative content analysis fits the use case of Bayesian multilevel regression analysis. Although there is another methodological introduction to Bayesian analysis aiming at communication researchers [@konijn:2015:PSP], the main purpose of this paper is to demonstrate how to practically implement one using the R package *brms* [@burkner2017advanced]. As the interface of *brms* is almost the same as *lme4* [@bates:2015:FLM, another R package for fitting multilevel models using MLE], *lme4* users might find *brms* extremely familiar. The above quoted challenge about the prescription of more widespread use of Bayesian methods for multilevel modelling is no longer an issue. 

# Methods

We used the useNews dataset [@puschmann:2020] to demonstrate how to perform a typical Bayesian multilevel regression analysis. The analysis was guided by a classic question in news value research: Does the distance between China and the host country of a media outlet increase the frequency of China coverage? In other words, we studied the ecological effect of the distance from China on the frequency of China coverage. Several distance measures were used to formulate our pre-registered hypotheses: physical distance between two capitals, trade volume between two countries, and cultural distance between two societies.

For demonstrative purposes, our analysis was separated into two levels: outlet-level analysis and article-level analysis. The outlet-level analysis is an aggregated version of article-level analysis. It is used to demonstrate the flexibility of Bayesian analysis to handle two-level data with very small data size. The article-level analysis is used to demonstrate the analysis of a massive three-level dataset.

## Data

The useNews is an openly available dataset [@puschmann:2020] that includes media content data from an array of worldwide media outlets from 2019 to 2020. The media content data was collected from the MIT MediaCloud and made available as document-term matrices.

We used only the data from 2019 as the baseline. It is important to note that the Hong Kong protests, the 30th anniversary of the Tiananmen Square Protests and the 70th anniversary of the communist regime were in that year. Also, it was in the zenith of the US-China trade war. 

We excluded media outlets that contributed <1000 articles in that year. This threshold allowed us to retain media outlets that the frequency of China coverage can be reliably estimated. In total, 61 media outlets from Spain (n = 11), Romania (n = 11), US (n = 7), Austria (n = 6), Germany (n = 5), Norway (n = 5), Australia (n  = 4), Brazil (n = 4), UK (n = 4), South Korea (n = 2), and the Netherlands (n = 2) were included. These 61 media outlets contributed 1,525,871 articles.

In the outlet-level analysis, the data has 61 rows and each row represents a media outlet. The data contains a count of articles covering China ($z$), total number of articles ($n$), country of the outlet($k$), and distance measures ($x$).

In the article-level analysis, the data has 1,525,871 rows and each row represents an article. The data contains a binary dependent variable of China coverage ($y$), media outlet($j$), country of the outlet($k$), and distance measures ($x$).

## Coverage of China

A dictionary-based approach was used. The seed English and German dictionaries from the R package newsmap [@watanabe:2017:N] were used as the basis. The seed dictionaries contain words about Chinese, China, Beijing and Shanghai. We developed further the Spanish, Romanian, Korean, Portugese, Norwegian, and Dutch dictionaries. The dictionaries were applied to the 61 DTMs of all included media outlets. An article is classified as China coverage when at least one dictionary match is detected.

<!-- ```{r, echo = FALSE} -->
<!-- Language <- c("English", "German", "Spanish", "Romanian", "Korean", "Portugese", "Norwegian", "Dutch") -->

<!-- Lexicon <- c("chinese, china, beijing, shanghai", "chinesisch*, chinesin*, chinese*, china*, peking, shanghai", "chino*, china*, pekin, shanghái", "chinez*, china, beijing, shanghai", "중국인, 중화, 중국, 베이징, 북경, 상하이, 상해", "chinês, chines*, china, pequim, xangai", "kineser*, kinesar*, kinesisk, kina, beijing, shanghai", "chinezen, chinees*, chinezin*, chines*, china, peking, beijing, sjanghai, shanghai") -->
<!-- papaja::apa_table(data.frame(Language, Lexicon), caption = "Dictionaries used for detecting China coverage") -->
<!-- ``` -->

## Distance measures

Several distance measures were used as the independent variable to test our central research questions: physical distance, trade volume, and cultural distance. Physical distance is calculated as the Great-circle distance between Beijing and the capital of the hosting city of the media outlet (e.g. Bucharest). The volumes of import to and export from China with the host country of a media outlet was extracted from the 2019 edition of China Statistical Yearbook (http://www.stats.gov.cn/tjsj/ndsj/2019/indexeh.htm). Cultural distance from China to the host country of a media outlet was extracted from culturaldistance.com, which was calculated using the data from World Value Survey with the algorithm from @bell:2009:C. All of these distance measures were log-transformed.

## Modeling

For all analyses, we tried 3 different approaches: 1) Disaggregation approach (ignoring the multilevel structure); 2) Multilevel regression using MLE; and 3) Bayesian multilevel regression. It is important to remind our readers that the results from the three are likely to be similar, but it is not an evidence for the disaggregation approach and the MLE approach are replacement of Bayesian approach. It is because disaggregation approach commits atomistic fallacy and MLE approach ignores the non-stochastic nature of the data.
 
### Outlet-level analysis

We used negative binomial regression for this analysis. Media outlets are nested in countries (e.g. *Der Standard* and *Österreichischer Rundfunk* are nested in Austria). Thus, a country-based variance is added ($\mu_{0k}$). We also added $\log{n_{j}}$ as an offset value. An offset value is a term that does not have the associated regression coefficient at the right-hand side of the regression equation \@ref(eq:2). Effectively, we modeled the *rate* of China coverage. Applying the same notation under the introduction section, the multilevel regression equations are:

\begin{align}
\log{z_{jk}} &= \gamma_{00} + \mu_{0k} + \gamma_{01} x_{k} + \log{n_j} + \epsilon_{jk} \\
\log{z_{jk}} - \log{n_j} &= \gamma_{00} + \mu_{0k} + \gamma_{01} x_{k} +  \epsilon_{jk} \\
\log\frac{z_{jk}}{n_{j}} &= \gamma_{00} + \mu_{0k} + \gamma_{01} x_{k} + \epsilon_{jk} \\
\end{align}

In lme4 and brms, the equation is expressed as such:

```r
# brms
brms::brm(z ~ offset(log(n)) + (1|k)+log(x),
          family = negbinomial(), data = outlet_data)
# lme4
lme4::glmer.nb(z ~ offset(log(n)) + (1|k) + log(x), data = outlet_data)
```


In the disaggregation case, the multilevel structure is ignored and the regression equation becomes:

\begin{align}
\log\frac{z_{jk}}{n_{j}} &= \beta_{0} + \beta_{1} x_{k} + \epsilon_{j}
\end{align}

In MASS, it is expressed as such:

```r
MASS::glm.nb(z ~ offset(log(n)) + log(x), data = outlet_data)
```

We named the models with different independent variables as model A1-4 respectively (A1: log import volume; A2: log export volume; A3: log physical distance; A4: log cultural distance).

### Article-level analysis

We used logistic regression for this analysis. Due to the computational time needed to conduct the Bayesian regression in this case (it took 4 days on a regular computer), we only did the model with import volume as the independent variable.

In this analysis, an article is nested in its media outlet. The media outlet is in turn nested in its country. Two variance terms ($\mu_{0j}$ and $\mu_{00k}$) are needed. The multilevel regression equations are:

\begin{align}
p_{ijk} &= Pr(y_{ijk} = 1) \\
L_{ijk} &= \log{\frac{p_{ijk}}{1 - p_{ijk}}} \\
L_{ijk} &= \pi_{0} + \epsilon_{ijk} \\
\pi_{0} &= \beta_{00} + \mu_{0j} \\
\beta_{00} &= \gamma_{000} + \mu_{00k} + \gamma_{001} x_{k}
\end{align}

Or in lme4/brms code:

```r
brms::brm(y~(1|k/j)+log(x), family = bernoulli(), data = article_data)
lme4::glmmer(y~(1|k/j)+log(x), family = binomial(), data = article_data)
```


In the disaggregation case, the multilevel structure is ignored and the regression equations become:

\begin{align}
p_{ijk} &= Pr(y_{ijk} = 1) \\
L_{ijk} &= \log{\frac{p_{ijk}}{1 - p_{ijk}}} \\
L_{ijk} &= \beta_{0} + \beta_{1} x_{k} + \epsilon_{ijk} \\
\end{align}

In MASS, it is expressed as such:

```r
MASS::glm(y ~ log(x), family = binomial(), data = article_data)
```

We named this model as model B1.

### Priors

For the outlet-level analysis, there are four unknown parameters to be estimated: $\gamma_{00}$, $\mu_{0k}$, $\gamma_{01}$ and the negative binomial shape parameter $\phi$. For the article-level analysis, the four unknown paramters are $\gamma_{000}$, $\mu_{00k}$, $\gamma_{001}$ amd $\mu_{0j}$. The idea of choosing priors is to select a probable probability distribution for each of these unknown parameters.

Usually, the first step for choosing priors is to review previous studies and look for possible values to be used as our informative priors. Although @wu:2000:SDI is a possible reference point, we select not to use this because China was not studied. Also, the modeling technique was quite different from the current one.

In this analysis, we used weakly informative priors suggested by @lemoine:2019:M.

For regression coefficients, e.g. $\gamma_{00}$, we used a normal distribution of $\mathcal{N}(0, 1)$. For variance terms, e.g. $\mu_{0k}$, a student t-distribution of $\mathcal{t}(3, 0, 2.5)$ was used. A gamma distribution of $\mathcal{Gamma}(0.01, 0.01)$ was used for the shape parameter $\phi$.

All, except the prior for regression coefficients, are default priors suggested by *brms*. The prior can be set with the following R code.

```r
weaklyinformative_prior <- c(prior_string("normal(0, 1)",
                                          class = "b"),
                             prior_string("normal(0, 1)",
                                          class = "Intercept"))
# The sample_prior argument is optional. But useful for further analysis.
import_brms <- brms::brm(z~offset(log(n))+(1|k)+log(x_import),
          data = outlet_data, family = negbinomial(),
          prior = weaklyinformative_prior, sample_prior = TRUE)
import_brms
```

### Other parameters

Other parameters for Bayesian multilevel regression analysis control how the MCMC should be performed. Three parameters are important: number of iterations, number of chains and *adapt_delta*. It is not some magic numbers that you can plug and play. However, it is in general safe to use the default values, i.e. number of iterations = 2000, number of chains = 4 and *adapt_delta* = 0.8, unless MCMC shows evidence of nonconvergence. *brms* is smart enough to give suggestions on how to adjust these three values. Nonetheless, we provide a short guide on how to diagnose convergence.

# Regression results

Table \@ref(tab:t1) shows a summary of all models from outlet-level analysis using three different ways of modeling. The Bayesian multilevel regression gave the *posterior distribution*, $P(\theta | X)$, of the regression coefficient ($\gamma_{001}$). It is a distribution and therefore we need ways to display both the central tendency and spread of the distribution. By default, *brms* displays the mean and the 95\% high density interval (HDI). [^5] These two values represent the point and interval estimates of the regression coefficient.

[^5]: HDI is one representation of Bayesian credible interval. It is important to note that, like confidence interval, there should be no "correct" choice of the level of credibility, but some established conventions. We choose, like many published works [e.g. @stegmueller:2013:HMC; @kovic:2017:B; @chan2020high], the default value of 95\% is to maintain "compatibility" with traditional approach of reporting 95\% confidence interval. However, there is a general concern about this crediblity level as being unstable for Bayesian analysis [@kruschke2014doing]. Some Bayesians, notably, Andrew Gelman, reports very liberal 50\% credible intervals. @mcelreath2020statistical selects 89\% to show the arbitariness of the practice. @leeuw:2020:AAT select 90\%.

Consistently, point estimates are remarkably similar. Bayesian multilevel regression gave a wider 95% HDI than confidence intervals from frequentist methods. It is similar to previous studies [@stegmueller:2013:HMC; @elff:2020:MAF]. The results indicate that only a higher export or import volume with China and the host country of the media outlet is associated with more reporting China.

Table: (\#tab:t1) Point and interval estimates from outlet-level analysis using three different analytic strategies: Disaggregation approach, multilevel modeling using MLE and Bayesian multililevel modeling

| Model                           | Disaggregate ($\beta_{1}$, 95\% CI) | MLE ($\gamma_{01}$, 95\% CI) | Bayesian ($\gamma_{01}$, 95\% HDI) |
|:--------------------------------|:------------------------------------|------------------------------|------------------------------------|
| Model A1: Log import volume     | 0.25 (0.18, 0.33)                   | 0.25 (0.18, 0.33)            | 0.25 (0.18, 0.33)                  |
| Model A2: Log export volume     | 0.22 (0.14, 0.30)                   | 0.22 (0.13, 0.31)            | 0.22 (0.11, 0.33)                  |
| Model A3: Log Physical distance | -0.02 (-0.34, 0.24)                 | -0.10 (-0.55, 0.31)          | -0.12 (-0.63, 0.39)                |
| Model A4: Log Cultural distance | -0.45 (-1.26, 0.34)                 | -0.60 (-1.80, 0.55)          | -0.62 (-2.12, 0.78)                |

Model B1 confirms the above again (Table \@ref(tab:t2) ). Therefore, both article- and outlet-level analyses arrive at the same conclusion.

```{r t2, results = "asis"}
### TODO: to prim it further
require(brms)
require(parameters)
require(dplyr)
article_level <- readRDS("import_logit.RDS")
article_level %>% parameters(ci = 0.95, effects = "fixed", dispersion = TRUE, centrality = "mean", test = "pd") %>% as.data.frame -> res

res %>% dplyr::select(Parameter, Mean, SD, CI_low, CI_high) %>% rename(Estimate = Mean) %>% knitr::kable(format = "markdown", caption = "Bayesian multilevel logistic regression analyzing the article-level likelihood of China coverage in relation to log import volume of the outlet's country", digits = 2)
```

## Diagnosis of convergence

It is important to confirm the model is converged. We demonstrate how to confirm this with model A1.

The first step is Gelman-Rubin convergence diagnostic [@brooks:1998:GMM; @vehtari:2020:RNF]. *brms* displays this in the form of $\widehat{R}$. In general, $\widehat{R} \approx 1$. The model might not have converged, when $\widehat{R} \ge 1.01$ [@vehtari:2020:RNF]. The *summary()* function of brms displays the $\widehat{R}$ for each of the estimated unknown parameters. All parameter estimates have a $\widehat{R} = 1.0$.

The second step is the MCMC trace plot (can be obtained with the function *plot()*). The traceplot should display the so-called "fuzzy caterpillar" pattern (Figure \@ref(fig:fig1)). There should be no breakage.

```{r fig1, echo = FALSE, fig.cap = "The right panel in the MCMC trace plot from plot() function showing the fuzzy catepillar pattern."}
require(brms)
import_brms <- readRDS("import_brms.RDS")
plot(import_brms)
```

An additional check is to study the autocorrelation of all chains. The correlogram should display low serial correlation (successive high correlation). The function *mcmc_plot* can be used to plot this (Figure \@ref(fig:fig2)).

If the diagnostics show evidence of nonconvergence, it is suggested to increase the number of iterations and number of chains. 

```{r fig2, echo = FALSE, fig.cap = "Correlogram of four chains showing no significant higher-order lag"}
mcmc_plot(import_brms, type = "acf")
```

## Further diagnostics

There are several diagnostic checks that we can do to make sure our model is valid.

* Increasing number of iterations

The first test is to increase the number of iterations from 2000 to a higher value, e.g. 4000, and see if the result is consistent with the initial analysis. This check makes sure our result is not transient due to short iteration time.

Increasing the number of iterations did change a bit of the estimates, but only at the second decimal place. It shows that the results are consistent between two analyses.

* Using another weakly informative prior

We can also use another weakly informative prior to see how our initial choice influence the result. We tried another weakly informative prior for the regression coefficients, $\mathcal{t}(1, 0, 0.25)$ [@gelman:2008]. Similarly, changing prior only impacts the second decimal place of the estimates.

* Posterior predictive checks

We can use posterior predictive checks to study how our model fits our data. The gist of the method is to use the fitted model to generate some simulated data ($y_{rep}$) and compare them with the original data ($y$). A good model should display a similar probability distribution of $y_{rep}$ and $y$. It can be done with the function *pp_check()* (Figure \@ref(fig:fig3) ).

```{r fig3, echo = FALSE, fig.cap = "Posterior predictive checks with 100 sets of simulated data"}
pp_check(import_brms, nsamples = 100)
```


# Discussion

Instead of arguing the advatnages of Bayesian multilevel regression analysis once again like we did in the introduction, we propose several extensions to the above barebone analysis. The analyses in these extensions are not preregistered.

## Extension #1: Hypothesis testing

Under the Bayesian framework, we can test hypotheses about the parameter estimates [@shikano:2019:HTB]. These hypotheses are similar to the null hypothesis in the Neyman-Pearson's sense. For example, we want to test the two-sided hypothesis of $\gamma_{01} = 0$ for Model A1. For this, we need to calculate the posterior probability of this hypothesis: $P(\gamma_{01} = 0 | X)$. The function *hypothesis()* can be used to test such hypothesis.

```r
hypothesis(import_brms, "logx_import = 0")
```

The posterior probability of this hypothesis is 0. Therefore, we can safely reject the hypothesis and conclude that $\gamma_{01} \neq 0$, i.e. log import volume of the outlet's country is associated with the frequency of China coverage at the outlet level.

Another approach suggested by @kruschke:2018:RAP, which uses the region of practical equivalence (ROPE), is available from the package bayestestR [@makowski:2019].

## Extension #2: Cross-level interaction

We can also study the interaction between a macro- and a micro-level variable. Cross-level interaction is useful to study how the effect of context variables manifest differently in individuals with different characteristics. An example of cross-level interaction in our example is whether the relationship between import volume and increase in China coverage manifests differently between public broadcasters and for-profit media. 

We can model a cross-level interaction by adding an interaction term between the macro- and micro-level variables, as well as a varying-slope component for the micro-level variable [@heisig:2019:WYS]. With *brms*, it can be done with this:

```r
# suppose "public" is a binary variable
import_brms_public <- brms::brm(
      z~offset(log(n))+(1 + public|k)+log(x_import)*public,
      data = outlet_data, family = negbinomial(),
      prior = weaklyinformative_prior, sample_prior = TRUE)
import_brms_public
```

The regression coefficients for the main effect of public broadcasting and the interaction terms have a wide 95\% HDI that covers zero. It can be visualized with a conditional effects plot (Figure \@ref(fig:fig4), using the *conditional_effects()* function). The trajectories of public broadcastors and for-profit media outlets are similar, indicating no interaction.

```{r fig4, echo = FALSE, fig.cap = "Conditional effects plot showing no interaction among public broadcasting, import volume and China coverage."}
require(ggplot2)
condit_plots <- readRDS("condit_plots.RDS")
condit_plots$`x_import:public` + xlab("Import Volume") + ylab("Number of articles mentioning China per 10,000 articles") + scale_x_continuous(labels = scales::comma) + theme_minimal() + scale_color_brewer(palette = "Dark2") + scale_fill_brewer(palette = "Dark2")
```

## Extension #3: Current study as the informative prior for the next study

Suppose we would like to replicate the study and confirm the same relationship with the 2020 useNews data. This time, we do not need to (and actually, we should not) use the weakly informative prior again. It is because we have *prior* understanding about the outlet-level determinants of China coverage: We know from the 2019 data that $\gamma_{01}$ should be around 0.25 with a standard deviation of 0.05. This can be entered into our new analysis as the informative prior.

```r
informative_prior <- c(prior_string("normal(0.25, 0.05)", class = "b",
                                    coef = "logx_import"),
                       prior_string("normal(-6.69, 0.66)",
                                    class = "Intercept"))
import_2020 <- brm(z_2020~offset(log(n_2020))+(1|k)+log(x_import),
                   data = outlet_data2020, family = negbinomial(),
                   prior = informative_prior, sample_prior = TRUE)
```

The new analysis showed that $\gamma_{01}$ is 0.22 with a 95\% HDI of (0.15 to 0.29) for the year 2020. This analysis displays two things: 1) selection of prior is not always, as many authors have suggested, as controversial and subjective; and 2) Bayesian analysis also makes a strong case for replication studies, what open science hopes to enable [@dienlin:2020:AOS].

## Extension #4: Temporal changes

Bayesian multilevel regression analysis is also useful to study temporal changes, because observations from the same subject collected from different time points are naturally a cluster. The same strategy for handling the clustering of observations in the multilevel modeling can be used. We model observations from the same media outlet are nested within the media outlet and then the media outlet is nested within its countries. Suppose we would like to study if there is a systematic increase in $z$ across all outlets, maybe due to the COVID-19 pandemic and the presidential election in the US. It can be analyzed with this 3-level model.

```r
## Suppose yr is a binary dummy variable indicating the year 2020.
import_long <- brm(z~offset(log(n))+(1|k/i)+yr, data = outlet_long,
                   family = negbinomial(),
                   prior = weaklyinformative_prior,
                   sample_prior = TRUE)
import_long
```

The regression coefficient for the year dummy variable is 0.49 (95\% HDI 0.38, 0.60). It seems that there is a global increase in China coverage from 2019 to 2020.

# Contributions

In this paper, we argue the case for using Bayesian multilevel regression analysis to analyse data from comparative content analyses. We demonstrate using the openly available useNews dataset that Bayesian analysis provides valid inference of ecological effects and can be done easily with the R package *brms*.

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup

